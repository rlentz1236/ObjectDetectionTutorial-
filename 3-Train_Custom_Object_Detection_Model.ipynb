{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50ffd939",
   "metadata": {},
   "source": [
    "# Train Custom Object Detection Model\n",
    "\n",
    "**Warning:** This notebook assumes that you have run the Object Detection Workspace Setup notebook and have a configured workspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f29cd0",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "https://github.com/nicknochnack/TFODCourse <br>\n",
    "**Highly Recommend Watching the Tensorflow Object Detection Walkthrough Video**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649b1009",
   "metadata": {},
   "source": [
    "### Required Dependicies \n",
    "pip install typeguard pytz gin-config tensorflow-addons "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb8db20",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06e3be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ced5568",
   "metadata": {},
   "source": [
    "## 2. Setup Paths to Workspace & Specify Pre-Trained Model\n",
    "\n",
    "Tensorflow 2 Detection Model Zoo: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
    "\n",
    "To copy a new model link go to the page above and right click any of the model names in the table, then select copy link address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cff8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set name for your custom object detection model\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_modnet' \n",
    "\n",
    "#Copy link from Tensorflow 2 Destection Model Zoo \n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "#Set to the name of the file downloaded by the link above - DO NOT INCLUDE the file extension\n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "\n",
    "#Sets Label Category - Determined by training dataset\n",
    "LABEL_MAP_NAME = 'custom_label_map.pbtxt'\n",
    "\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "\n",
    "#Set project location and directory name\n",
    "PROJECT_NAME = \"C:\\\\Users\\Richard\\\\Desktop\\\\ObjDetection_Workspace\\\\\"\n",
    "\n",
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join(PROJECT_NAME, 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join(PROJECT_NAME,'scripts'),\n",
    "    'APIMODEL_PATH': os.path.join(PROJECT_NAME,'models'),\n",
    "    'ANNOTATION_PATH': os.path.join(PROJECT_NAME, 'workspace','custom_models', CUSTOM_MODEL_NAME, 'annotations'),\n",
    "    'IMAGE_PATH': os.path.join(PROJECT_NAME, 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join(PROJECT_NAME, 'workspace','custom_models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join(PROJECT_NAME, 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join(PROJECT_NAME, 'workspace','custom_models',CUSTOM_MODEL_NAME),\n",
    "    'LABEL_PATH': os.path.join(PROJECT_NAME, 'workspace','custom_models',CUSTOM_MODEL_NAME, 'label_map'),\n",
    "    'OUTPUT_PATH': os.path.join(PROJECT_NAME, 'workspace','custom_models',CUSTOM_MODEL_NAME, 'final_model'), \n",
    "    'TFJS_PATH': os.path.join(PROJECT_NAME, 'workspace','custom_models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH': os.path.join(PROJECT_NAME, 'workspace','custom_models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    "    'PROTOC_PATH': os.path.join(PROJECT_NAME,'protoc'),\n",
    "    'TRAIN_PATH': os.path.join(PROJECT_NAME, 'workspace','images','train'),\n",
    "    'TEST_PATH': os.path.join(PROJECT_NAME, 'workspace','images','test')\n",
    " }\n",
    "\n",
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join(PROJECT_NAME, 'workspace','custom_models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['LABEL_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9053e60c",
   "metadata": {},
   "source": [
    "## 3. Create Folders in Workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a1c534",
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a69b79fe",
   "metadata": {},
   "source": [
    "## 4. Copy Training & Testing Data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5237a358",
   "metadata": {},
   "source": [
    "**Training and Testing data must be downloaded or manually created using a program like LabelImg**\n",
    "\n",
    "**1.** Copy all training images along with thier annotation xml file to workspace/images/train\n",
    "<br> <br>\n",
    "**2.** Copy all testing images along with thier annotation xml file to workspace/images/test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7793a2ca",
   "metadata": {},
   "source": [
    "## 5. Download Pre-trained Model\n",
    "**Checks to see if it exist already before downloading**\n",
    "\n",
    "**Download Location:** workspace/pretrained-models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c807c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME)):\n",
    "    if os.name =='posix':\n",
    "        !wget {PRETRAINED_MODEL_URL}\n",
    "        !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "        !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "    if os.name == 'nt':\n",
    "        wget.download(PRETRAINED_MODEL_URL)\n",
    "        !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "        !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "else:\n",
    "    print(\"Model Already Downloaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3da38a",
   "metadata": {},
   "source": [
    "## 6. Create Label Map pbtxt File\n",
    "This cell creates the pbtxt file that your model will use to make predictions. The name of the file is set by the LABEL_MAP_NAME variable. <br>\n",
    "The labels given here MUST MATCH the labels given to your image dataset. Otherwise an error will be generated when you try to run train your custom model.\n",
    "\n",
    "**Format:** {'name':'CustomLabel', 'id':1}\n",
    "\n",
    "Make sure to increase the id value by 1 for each label in your dataset. <br>\n",
    "**Example:** {'name':'CustomLabel1', 'id':1}, {'name':'CustomLabel2', 'id':2}, {'name':'CustomLabel3', 'id':3}, {'name':'CustomLabel4', 'id':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98eb4402",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [ {'name':'ThumbsUp', 'id':1}, {'name':'LiveLong', 'id':2} ]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')\n",
    "\n",
    "print(\"Label Map Created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36ed278",
   "metadata": {},
   "source": [
    "## 7. Create TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d7177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if generate_tfrecord.py script has been downloaded\n",
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}\n",
    "        \n",
    "        \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} \n",
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1f4da4",
   "metadata": {},
   "source": [
    "## 8. Copy Pre-Trained Model Config to Custom Model Folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd737b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0e8b2a",
   "metadata": {},
   "source": [
    "## 9. Update Config For Transfer Learning\n",
    "\n",
    "**Make sure to change the *pipeline_config.model.MODELTYPE.num_classes = len(labels)* to match the pre-trained model type specfied**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f242cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef40a4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data from current config file\n",
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "\n",
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config)  \n",
    "\n",
    "\"\"\" \n",
    "Depending on the model type being used the line below will need to be changed.\n",
    "\n",
    "If using Faster or Mask pre-trained model set line to\n",
    "pipeline_config.model.faster_rcnn.num_classes = len(labels)\n",
    "\n",
    "If using SSD or EfficientDet pre-trained model set line to\n",
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "\n",
    "If using CenterNet pre-trained model set line to\n",
    "pipeline_config.model.center_net.num_classes = len(labels)\n",
    "\"\"\" \n",
    "pipeline_config.model.ssd.num_classes = len(labels)\n",
    "\n",
    "#Sets location of training record, test record, and checkpoint files\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]\n",
    "\n",
    "#Create new config file\n",
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b26956f",
   "metadata": {},
   "source": [
    "## 10. Create Train Model Command\n",
    "**Copy printed command and run in terminal window**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e341e822",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set number of training steps - Should be 10000-20000 for a full run - Use 1000-2000 for a quick test\n",
    "training_steps = 5000\n",
    "\n",
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')\n",
    "\n",
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], training_steps)\n",
    "\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0bb8c7",
   "metadata": {},
   "source": [
    "## 11. Evaluate the Model\n",
    "**Copy printed command and run in terminal window** <br>\n",
    "**Press ctrl+c in terminal to exit Evaluation Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4037fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])\n",
    "\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba5be931",
   "metadata": {},
   "source": [
    "### Run Tensorboard \n",
    "**Run cell below and go to the following link:** http://localhost:6006/  <br>\n",
    "**Press ctrl+c in terminal to exit Evaluation Script**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04a838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "command = \"tensorboard --logdir=\" + os.path.join(paths['CHECKPOINT_PATH'], 'eval')\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c51dbf6",
   "metadata": {},
   "source": [
    "## 12. Import Libraries Needed to Run Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e11b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "import cv2 \n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1225b5a5",
   "metadata": {},
   "source": [
    "## 13. Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be0977d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set checkpoint file to load\n",
    "checkpoint = 'ckpt-1'\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], checkpoint)).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8690b299",
   "metadata": {},
   "source": [
    "## 14. Set Objects to Detect & Image to Detect them on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905b73fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sets the pbtxt file to use - specified by LABEL_MAP_NAME variable \n",
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])\n",
    "\n",
    "#Sets image to do object prediction on \n",
    "IMAGE_PATH = (\"C:\\\\Users\\Richard\\\\Desktop\\\\thumbsup.cd56334e-ff92-11ec-9566-84144db13b80.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056583b4",
   "metadata": {},
   "source": [
    "## 15. Run Object Detection for Given Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb202cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(IMAGE_PATH)\n",
    "image_np = np.array(img)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "detections = detect_fn(input_tensor)\n",
    "\n",
    "num_detections = int(detections.pop('num_detections'))\n",
    "detections = {key: value[0, :num_detections].numpy()\n",
    "              for key, value in detections.items()}\n",
    "detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "label_id_offset = 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "            image_np_with_detections,\n",
    "            detections['detection_boxes'],\n",
    "            detections['detection_classes']+label_id_offset,\n",
    "            detections['detection_scores'],\n",
    "            category_index,\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=5,\n",
    "            min_score_thresh=.8,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "plt.imshow(cv2.cvtColor(image_np_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089c685d",
   "metadata": {},
   "source": [
    "## 16. Freezing the Model's Graph & Save for Later\n",
    "**Copy printed command and run in terminal window**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88126b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')\n",
    "\n",
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])\n",
    "\n",
    "print(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b66060f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
